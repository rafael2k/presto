<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html lang="en" dir="ltr">
<head>
 <meta http-equiv="Content-Type" content="text/html;charset=utf-8">
 <title>Unicode module</title>
 <link rev="made" href="mailto:peter@opera.com">
 <link rel="stylesheet" href="../../coredoc/coredoc.css" type="text/css" media="all">
 <link rel="contents" href="../../coredoc/index.html" type="text/html" title="Core API">
 <link rel="next" href="segmenter.html" type="text/html">
 <style type="text/css">
  a[href^="http://www.unicode.org/"]:after { content: " (external link)"; }
  ul#tocUl { list-style: none; padding-left: 0; }
 </style>
 <script type="text/javascript" src="../../coredoc/createtoc.js"></script>
</head>

<body>
 <h1>Unicode module</h1>
 <p id="toc">
  Copyright © 1995-2012 Opera Software ASA. All rights reserved.
  This file is part of the Opera web browser. It may not be distributed
  under any circumstances.
 </p>

 <h2 id="introduction">Introduction</h2>
 <p>
  The <em>Unicode module</em> gives access to the available from the
  Unicode database.
 </p>

 <p>
  <a href="http://wiki.oslo.opera.com/developerwiki/index.php/Modules/unicode">Current
  information about the Unicode module</a>.
 </p>

 <p>
  For a definition of terms used in this document, please refer to the
  <a href="http://www.unicode.org/glossary/">Unicode glossary</a>.
 </p>

 <h2 id="interfaceoverview">
  Interface overview and
  <abbr title="Application programming interface">API</abbr>
  documentation
 </h2>
 <h3 id="apidocumentation">API documentation</h3>
 <p>
  The
  <a href="api/index.html">API documentation</a>
  is extracted automatically by Doxygen.
 </p>

 <h3 id="overview">Overview</h3>
 <p>
  Most of the public API of this module of this module is exported through the
  <a href="api/classUnicode.html"><code>Unicode</code> class</a>.
  This class is never instantiated, but instead used as a namespace.
  The <code>Unicode</code> class has six types of functionality:
 </p>
 <ol>
  <li>Normalization</li>
  <li>Line breaking</li>
  <li>Case conversion</li>
  <li>Property lookup</li>
  <li>Directionality lookup</li>
  <li>Script-type lookup</li>
 </ol>
 <p>
  Please read the <a href="api/index.html">API documentation</a>
  and below for details.
 </p>
 <p>
  The
  <a href="api/classUTF8Decoder.html"><code>UTF8Decoder</code></a> and
  <a href="api/classUTF8Encoder.html"><code>UTF8Encoder</code></a> classes
  implement stand-alone support for converting from and to the
  <abbr title="UCS Tranformation Format">UTF</abbr>-8 encoding form.
  The <a href="../../encodings/documentation/index.html">encodings module</a>
  uses classes derived from these when decoding UTF-8 data through the
  CharConverter framework.
 </p>
 <p>
  Unicode defines the type <code>UnicodePoint</code> used to 
  represent a single code point. Functions operating on on
  single code points typically takes this a the argument. To
  use these correctly the calling code needs to decode surrogate
  pairs into <code>UnicodePoint</code>'s. See <a href="#surrogatepairs">
  Handling surrogate pairs<a/> for more information.
 </p>
 <p>
  The
  <a href="api/classUnicodeSegmenter.html"><code>UnicodeSegmenter</code>
  class</a>
  supports segmentation of text,
  <a href="#textsegmentation">see below</a> for more information.
 </p>
 <p>
  The <a href="api/classUnicodeStringIterator.html"><code>UnicodeStringIterator</code></a>
  is a utility class for iterating through strings.
 </p>
 <p>
  The
  <a href="api/classBidiStatus.html"><code>BidiStatus</code></a>,
  <a href="api/classParagraphBidiSegment.html"><code>ParagraphBidiSegment</code></a>
  and
  <a href="api/classBidiCalculation.html"><code>BidiCalculation</code></a>
  classes implement the Unicode bidirection algorithm,
  <a href="#bidiutils">see below</a> for more information.
 </p>
 <p>
  Some algorithms have been
  <em><a href="tailoring.html">tailored</a></em>
  to suit Opera and the web.
 </p>

 <h3 id="surrogatepairs">Handling surrogate pairs</h3>
 <p>
  When dealing with single unicode points you need to be aware of surrogate
  pairs. Functions operating on <code>UnicodePoint</code>'s need the full
  unicode point therefor any surrogate pairs need to be decoded before
  beeing passed.
  When using function that operates on strings (<code>uni_char*</code>) this
  is done internally and no special handling is required by the caller.
 </p>
 <p>
  To help the users Unicode provides a couple of helper functions. 
  <code><a href="api/classUnicode.html">Unicode</a>::DecodeSurrogate()</code>
  and <code><a href="api/classUnicode.html">Unicode</a>::MakeSurrogate()</code>
  can be use decode and separate pairs respectively. To iterate through a string
  <code><a href="api/classUnicode.html">Unicode</a>::GetUnicodePoint()</code>
  can be used.
 </p>

 <h2 id="usecases">Use-cases</h2>
 <h3 id="transformation">Converting to and from UTF-8 and UTF-32</h3>
 <p>
  Opera internally stores all text in the UTF-16 format, but this is just one
  of the several transformation formats that can be used for Unicode text.
  For byte-oriented storage and network protocols, the UTF-8 encoding is well
  suited.
 </p>
 <p>
  Use
  <code><a href="api/classUTF8Encoder.html">UTF8Encoder</a>::Measure()</code></a>
  to determine the space requirements for storing a piece for UTF-16 text in
  UTF-8 format, and
  <code><a href="api/classUTF8Encoder.html">UTF8Encoder</a>::Convert()</code></a>
  to convert.
 </p>
 <p>
  Conversly, use
  <code><a href="api/classUTF8Decoder.html">UTF8Decoder</a>::Measure()</code></a>
  to determine the space requirements for storing a piece of UTF-8 text in
  UTF-16 format (note that the return value is in bytes, not in UTF-16 code
  units), and
  <code><a href="api/classUTF8Decoder.html">UTF8Decoder</a>::Convert()</code></a>
  to convert.
 </p>
 <p>
  Some systems internally make use of the UTF-32 encoding (notably those using
  the GNU C library, glibc) for its one-to-one mapping between Unicode
  code-points and 32-bit integer values.
  If <code>API_UC_UTF32_CODECS</code> is imported from the Unicode module,
  the classes
  <code><a href="api/classUTF32Encoder.html">UTF32Encoder</a></code> and
  <code><a href="api/classUTF32Decoder.html">UTF32Decoder</a></code> are made
  available for conversion from and to the internally used UTF-16 encoding.
  Their APIs mirror those of the UTF-8 classes described above.
 </p>
 <p>
  UTF-32 data is only supported when encoded in the machine endian of the
  running binary.
 </p>

 <h3 id="normalization">String normalization</h3>
 <p>
  Use <code><a href="api/classUnicode.html">Unicode</a>::Normalize()</code>
  to convert any string of UTF-16 code units into one of the four
  Unicode normalization forms NFC, NFKC, NFD and NFKD.
 </p>
 
 <h3 id="narrowwidedecomposition">Narrow/Wide decomposition</h3>
 <p>
  Use <code><a href="api/classUnicode.html">Unicode</a>::DecomposeNarrowWide()</code>
  to replace all fullwidth and halfwidth characters (those defined with decomposition types &lt;wide&gt; and &lt;narrow&gt;) to their decompositions.
 </p>

 <h3 id="caseconversion">Case conversion</h3>
 <p>
  Use <code><a href="api/classUnicode.html">Unicode</a>::ToUpper()</code>
  and <code><a href="api/classUnicode.html">Unicode</a>::ToLower()</code>
  to convert a single character to a specific case.
 </p>
 <p>
  Use <code><a href="api/classUnicode.html">Unicode</a>::Upper()</code>
  and <code><a href="api/classUnicode.html">Unicode</a>::Lower()</code>
  to convert a nul-terminated string, either in-place or out-of-place.
 </p>
 
 <h3 id="casefolding">Case folding</h3>
 <p>
    Case folding can be an important part of normalizing text for comparison purposes. 
    The main difference between simple case folding and full case folding is that the first doesn't change 
    the string length while the latter can. Note that where they can be supported, the full case foldings 
    are superior: for example, they allow "MASSE" and "Maße" to match.
 </p>
 <p>
	For more information about case folding please read section 3.13 "Default Case Algorithms" in The Unicode Standard 5.2.
 </p>
 <p>
  Use <code><a href="api/classUnicode.html">Unicode</a>::ToCaseFoldFull(const uni_char *)</code>
  to perform full case folding of every character in the specified UTF-16 encoded string.
 </p>
 <p>
  Use <code><a href="api/classUnicode.html">Unicode</a>::ToCaseFoldFull(UnicodePoint, UnicodePoint *)</code>
  to perform full case folding for the specified single Unicode codepoint.
 </p>
 <p>
  Use <code><a href="api/classUnicode.html">Unicode</a>::ToCaseFoldSimple()</code>
  to perform simple case folding on the specified Unicode codepoint.
 </p>
 
 <h3 id="classlookup">Class lookup</h3>
 <p>
  Use <code><a href="api/classUnicode.html">Unicode</a>::GetCharacterClass()</code>
  to retrieve information
  about the Unicode character class for a specific UTF-16 code unit.
 </p>
 <p>
  There are also several convenience APIs, such as
  <code><a href="api/classUnicode.html">Unicode</a>::IsUpper()</code>
  to check for one or more specific classes.
 </p>

 <h3 id="propertylookup">Extended property lookup</h3>
 <p>
  Use <code><a href="api/classUnicode.html">Unicode</a>::CheckPropertyValue()</code>
  to retrieve value of one of the Unicode extended character properties for a specific Unicode codepoint.
 </p>
 <p>
  The list of available properties to loookup for is defined by enum UnicodeProperties.
 </p>

 <h3 id="derivedpropertylookup">Derived property lookup</h3>
 <p>
  Use <code><a href="api/classUnicode.html">Unicode</a>::CheckDerivedPropertyValue()</code>
  to retrieve value of one of the Unicode derived character properties for a specific Unicode codepoint.
 </p>
 <p>
  The list of available derived properties to loookup for is defined by enum UnicodeDerivedProperties.
 </p>
 
 <h3 id="blocktypelookup">Block type lookup</h3>
 <p>
  Use <code><a href="api/classUnicode.html">Unicode</a>::GetUnicodeBlockType()</code>
  to retrieve the Unicode block type for a specific Unicode codepoint.
 </p>
 <p>
  Possible blocks are defined by enum UnicodeBlockType (generated from Blocks.txt).
 </p>
 
 <h3 id="joiningtypelookup">Joining type lookup</h3>
 <p>
  Use <code><a href="api/classUnicode.html">Unicode</a>::GetUnicodeBlockType()</code>
  to retrieve the Unicode joining type for a specific Unicode codepoint.
 </p>
 <p>
  Possible joining types are defined by enum UnicodeJoiningType and are:
 </p>
 <dl>
  <dt>JT_R - Right-Joining</dt><dd>For example arabic letters: ALEF, DAL, THAL, REH, ZAIN</dd>
  <dt>JT_L - Left-Joining</dt><dd>Currently there is no character with this joining type in Unicode Character Database</dd>
  <dt>JT_D - Dual-Joining</dt><dd>For example arabic letters: BEH, TEH, THEH, JEEM</dd>
  <dt>JT_C - Join-Causing</dt><dd>U+200D zero width joiner and TATWEEL (0640). These characters are distinguished from the 
  dual-joining characters in that they do not change shape themselves.</dd>
  <dt>JT_U - Non-Joining</dt><dd>U+200C zero width non-joiner and all spacing characters, except those explicitly 
  mentioned as being one of the other joining types, are non-joining.</dd>
  <dt>JT_T - Transparent</dt><dd>All nonspacing marks (General Category Mn or Me) and most format control characters 
  (General Category Cf) are transparent to cursive joining.</dd>
 </dl>
 <p>
  For more information about joining types please read section 8.2 "Arabic" in The Unicode Standard 5.2.
 </p>
 
 <h3 id="linebreaklookup">Line breaking</h3>
 <p>
  Use
  <code><a href="api/classUnicode.html">Unicode</a>::IsLinebreakOpportunity()</code>
  to look up line breaking opportunities for two characters.
  The method
  <code><a href="api/classUnicode.html">Unicode</a>::GetLineBreakClass()</code>
  can be used to access the line-breaking class for a specific code point.
 </p>

 <h4 id="linebreaklookup_SA">Complex Context Dependent line breaking (South East Asian languages)</h4>
 <p>
  The second signature for
  <code><a href="api/classUnicode.html">Unicode</a>::IsLinebreakOpportunity()</code>
  performs line breaking that is aware of the <code>LB_SA</code> line-breaking
  class. The <code>LB_SA</code> class is used in some languages where SPACE is
  not used as a word separator, therefore line breaking (and word segmentation)
  depends on more in-depth knowledge of the language itself. Normally, for
  <code>LB_SA</code> text, this second signature for
  <code><a href="api/classUnicode.html">Unicode</a>::IsLinebreakOpportunity()</code>
  provides line breaking opportunities between every grapheme cluster (symbol).
  However, the code can be patched to do more sophisticated (typically
  language-dependent) line breaking algorithms.
 </p>
 <p>
  One such language-dependent algorithm is included:
  <code><a href="api/classFallbackThaiUnicodeLinebreaker.html">FallbackThaiUnicodeLinebreaker</a></code>.
  This class is derived from a simple and naive Thai line breaking algorithm
  <a href="http://userjs.org/scripts/browser/enhancements/thai-wrap">first implemented in UserJS</a>.
  This algorithm is far from 100% accurate, and instead uses a collection of
  data tables and very simple heuristics to insert line break opportunities.
  The data tables are:
 </p>
 <dl>
  <dt>Wordlist</dt><dd>A short list of (51) unambiguous Thai words</dd>
  <dt>LeadingChars</dt><dd>A list of Thai characters that might appear at the start of a word</dd>
  <dt>FollowingChars</dt><dd>A list of Thai characters that typically appears towards the end of a word</dd>
  <dt>EOWChars</dt><dd>A list of Thai characters that only appear at the end of a word</dd>
 </dl>
 <p>
  The algorithm then inserts line break opportunities in the following cases:
 <ul>
  <li>Following character followed by Leading character</li>
  <li>Thai character followed by non-Thai character</li>
  <li>Non-Thai character followed by Thai character</li>
  <li>Non-Leading character followed by a word from Wordlist</li>
  <li>Word from Wordlist followed by non-Following character - <strong>NOT implemented by
   <code><a href="api/classFallbackThaiUnicodeLinebreaker.html">FallbackThaiUnicodeLinebreaker</a>::IsLinebreakOpportunity()</code></strong></li>
  <li>Directly after End-of-word characters</li>
 </ul>
 </p>

 <h3 id="directionalitylookup">Directionality lookup</h3>
 <p>
  Use
  <code><a href="api/classUnicode.html">Unicode</a>::GetBidiCategory()</code>
  to retrieve directionality information for a specific UTF-16 code unit.
 </p>
 <p>
  Use <code><a href="api/classUnicode.html">Unicode</a>::IsMirrored()</code>
  and
  <code><a href="api/classUnicode.html">Unicode</a>::GetMirrorChar()</code>
  to look up mirroring information.
 </p>

 <h3 id="scripttypelookup">Script-type lookup</h3>
 <p>
  Use 
  <code><a href="api/classUnicode.html">Unicode</a>::GetScriptType()</code>
  to retrieve script type for a specific code point.
 </p>

 <h3 id="textsegmentation">Text segmentation</h3>
 <p>
  To find character (&ldquo;grapheme cluster&rdquo;), word, and sentence
  boundaries in text, use the
  <a href="api/classUnicodeSegmenter.html"><code>UnicodeSegmenter</code></a>
  class.
  To use it, you instantiate the object, determining which type of
  boundaries you wish to find, and iteratively call
  <code><a href="api/classUnicodeSegmenter.html">UnicodeSegmenter</a>::FindBoundary()</code>
  on the text.
  See the <a href="api/classUnicodeSegmenter.html">API documentation</a>
  for details on how to use it.
 </p>
 <p>
  There is a shortcut method
  <code><a href="api/classUnicodeSegmenter.html">UnicodeSegmenter</a>::IsGraphemeClusterBoundary()</code>
  that can
  be used if you need to check whether two UTF-16 code units should be
  kept together, either because of both belonging to the same surrogate
  character, or the second is an extension to the first (combining marks
  and similar).
 </p>
 <p>
  The text segmenter implementation is
  <a href="segmenter.html">documented separately</a>.
 </p>

 <h3 id="bidiutils">Bidirectional algorithm</h3>
 <p>
  To support bi-directional text and right-to-left languages (such as Arabic
  and Hebrew), this module contains an implementation of the
  <a href="http://www.unicode.org/reports/tr9/">The Unicode bidirectional
  algroithm</a>.
  This implementation is
  <a href="bidi.html">discussed in a separate document</a>.
 </p>

 <h3 id="updating">Updating data tables</h3>
 <p>
  The tables in the
  <a href="../data/"><code>data</code></a>
  subdirectory are retrieved from the
  <a href="http://www.unicode.org/Public/UNIDATA/">Unicode database</a>.
  When a new version of the database is released, these tables should be
  updated with the new files and the scripts in the
  <a href="../scripts/"><code>scripts</code></a>
  directory re-ran to update the generated files.
 </p>
 <p>
  To run the scripts, enter the
  <a href="../scripts/"><code>scripts</code></a>
  directory and type <kbd>make</kbd> to create the data.
  The generated files are committed to the version control system.
 </p>

 <h2 id="supportedstandards">Supported standards</h2>
 <p>
  The Unicode module is based on the
  <a href="http://www.unicode.org/Public/">data supplied by the Unicode
  Consortium</a>.
  The data and algorithms are currently up-to-date with version 6.1 of the
  standard.
 </p>
 <p>
  The following parts of the Unicode standard are supported by this module:
 </p>
 <ul>
  <li>
   <a href="http://www.unicode.org/versions/latest/">Core specification</a>:
   Unicode Encoding Forms: Unicode Tranformation Format 8 (UTF-8) and 32
   (UTF-32)
   (Version 6.1.0)
   <br>
   Conformance: D76&ndash;D81, D83&ndash;D90, D92, D93 (tested by selftest code).
  </li>
  <li>
   <a href="http://www.unicode.org/reports/tr15/"><abbr title="Unicode Standard Annex">UAX</abbr>#15</a>:
   Unicode normalization, NFC, NFD, NFKC and NFKD.
   (Revision 35)
   <br>
   Conformance: UAX15-C3 (tested by selftest code).
  </li>
  <li>
   <a href="http://www.unicode.org/reports/tr14/"><abbr title="Unicode Standard Annex">UAX</abbr>#14</a>:
   Unicode line breaking algorithm.
   (Revision 28)
   <br>
   Conformance: UAX14-C1 (tested by selftest code)
   <strong>for characters up to <code>U+2FFFF</code> only</strong>
   (<abbr title="Basic Multilingual Plane (U+0000-U+FFFF)">BMP</abbr>,
   <abbr title="Supplementary Multilingual Plane (U+10000-U+1FFFF)">SMP</abbr>
   and
   <abbr title="Supplementary Ideographic Plane (U+20000-U+2FFFF)">SIP</abbr>).
   <br>
   UAX14-C2 (UAX14-HL1, UAX14-HL2, UAX14-HL3) since mark-up languages
   makes a higher-level protocol.
   <br>
   <a href="tailoring.html#uax14">Tailoring details</a>.
  </li>
  <li>
   <a href="http://www.unicode.org/reports/tr29/"><abbr title="Unicode Standard Annex">UAX</abbr>#29</a>:
   Text segmentation.
   (Revision 18)
   <br>
   Conformance: There are no conformance criteria.
   We implement UAX#29 with only partial support for
   non-<abbr title="Basic Multilingual Plane (U+0000-U+FFFF)">BMP</abbr>
   characters.
   Extended grapheme clusters (rules GB9a and GB9b are not supported), only
   legacy grapheme clusters.
   <br>
   <a href="tailoring.html#uax29">Tailoring</a>
  </li>
  <li>
   <a href="http://www.unicode.org/reports/tr9/"><abbr title="Unicode Standard Annex">UAX</abbr>#9</a>:
   The Bidirectional Algorithm.
   <br />
   Conformance: Unknown.<!--### TODO -->
  </li>
  <li>
   Character properties.
   <br>
   Conformance: D9 partial, see below.
   <ul>
    <li>
     Case mapping.
     <br>
     Conformance: For all characters, special mappings not
     supported.
    </li>
    <li>
     Character classes.
     <br>
     Conformance: For characters up to <code>U+FFFF</code> only.
    </li>
    <li>
     Directionality properties.
     <br>
     Conformance: For characters up to <code>U+FFFF</code> only.
     
     </li>
    </ul>
  </li>
 </ul>

 <h2 id="implementationanddesign">Implementation and design</h2>
 <p>
  See also the
  <a href="api/index.html">API documentation</a>,
  <a href="segmenter.html">implementation of text segmenter</a>,
  <a href="bidi.html">implementation of the bidirectional algorithm</a>
  and
  <a href="tailoring.html">details on Opera-specific tailoring</a>.
 </p>

 <h3 id="memorymanagement">Memory management</h3>

 <h4 id="heapusage">Heap usage</h4>
 <p>
  The only code that allocates heap memory is the normalization code
  and out-of-place case conversion.
  The size of the allocated data is a function of the amount of data
  submitted to it.
  The memory allocated by it needs to be deallocated by the caller.
 </p>

 <h4 id="stackusage">Stack usage</h4>
 <p>
  The normalization code contains recursive calls for decomposing
  characters.
  Decomposing any single character should be fairly shallow, though.
  Composing characters is done iteratively.
 </p>

 <h4 id="staticmemoryusage">Static memory usage</h4>
 <p>
  There are no global pointers.
  The data obtained from the Unicode database is encoded in the binary
  image.
 </p>

 <h4 id="oompolicies"><abbr title="Out of memory">OOM</abbr> policies</h4>
 <p>
  Any out-of-memory conditions will be reported to, and must be handled by,
  the caller.
 </p>

 <h3 id="performance">Performance</h3>
 <p>
  To improve speed and reduce binary footprint, the data tables are
  compressed in various ways.
 </p>

 <h4 id="directionality">Directionality tables</h4>
 <p>
  The <strong>directionality (bidi) table</strong> is a run-length
  compressed table with mappings from UTF-16 code units to directionality
  classes.
  This table is binary-searched on lookup.
 </p>
 <p>
  The last block found is cached in the module, since there often are
  repeated calls requesting information for characters in the same block.
 </p>
 <p>
  The <strong>mirroring table</strong> is split into two for performance.
  The first table is sorted by UTF-16 code unit so that it can be binary
  searched.
  However, since this involves both code units there are some mappings that
  cannot be included it this table due to the mirroring ranges being
  overlapping.
  These special cases are added in a second table that is linearly-searched
  when lookup fails in the first table.
 </p>
 <p>
  The last value looked up is cached internally, since we use the same
  method for checking if a character is mirrored as to find its mirror image.
 </p>
 <p>
  The code using this tables is
  <a href="bidi.html">discussed in a separate document</a>.
 </p>

 <h4 id="case">Case conversion tables</h4>
 <p>
  The <strong>case conversion</strong> is implemented as a three-way table,
  with case conversion to both lower and upper case stored in the same table.
 </p>
 <p>
  The first table contains indices to the second.
  This table is binary searched for performance.
 </p>
 <p>
  The second table contains case conversion information data.
  The lower <code>CASE_INFO_BITS</code> contains an index to the third
  table, whose data are interpreted according to the following bits.
  The data from the third table is either a bit mask or a shift index.
 </p>
 <dl>
  <dt>Lower delta</dt>
  <dd>
   The value is a delta for converting from lower to upper case.
   When converting to upper case, this value is added to the
   input code point.
  </dd>

  <dt>Upper delta</dt>
  <dd>
   The value is a delta for converting from upper to lower case.
   When converting to lower case, this value is subtracted from the
   input code point.
  </dd>

  <dt>Double delta</dt>
  <dd>
   The value is a delta used for converting from title-case to either
   lower or upper case. When converting to upper case, this value is
   added to the input code point, and when converting to lower case,
   this value is subtracted from the input code point.
  </dd>

  <dt>Large lower delta</dt>
  <dt>Large uppder delta</dt>
  <dd>
   These are the same as the lower/upper delta, except that the
   value is to be multiplied by two.
   This allows for storing deltas up to 65536.
  </dd>

  <dt>Bit mask</dt>
  <dd>
   The value is a bit mask for converting the case, using OR will get
   the uppercase character, using AND on the inverted value will get
   the lowercase character.
  </dd>

  <dt>Bit mask offset</dt>
  <dd>
   The value is an offset bit mask for converting the case, with the
   same rules as for the bit mask type, but shifted by one codepoint.
  </dd>
 </dl>

 <p>
  Special cases:
  <ul>
  <li>
  The ASCII range (Basic Latin, <code>U+0000</code> to <code>U+007F</code>)
  is hardcoded into the lookup to improve performance.
  </li>
  <li>
  Non-BMP case conversions are stored in their pair table, due to the
  small number of such code points requiring case mapping.
  </li>
  </ul>
 </p>

 <h4 id="normalize">Normalization tables</h4>
 <p>
  The <strong>decomposition tables</strong> contains data directly from the
  Unicode database.
  The <abbr title="Basic Multilingual Plane (U+0000-U+FFFF)">BMP</abbr>
  table maps a single UTF-16 code unit into two single UTF-16 code
  units defining its decomposition.
  The non-BMP table maps one non-BMP codepoint expressed as a 32-bit value
  where the high word is the high surrogate and the low word is the low
  surrogate into two 32-bit values which in turn are either surrogate pairs
  or single BMP codepoints.
  These two characters are then in turn decomposed further.
 </p>
 <p>
  The <strong>compatibility decomposition table</strong> is a table with flag
  bits stating whether the decomposition for the character is a compatibility
  decomposition or not.
 </p>
 <p>
  The <strong>composition table</strong> contains the same information as the
  decomposition table, but sorted on the character to be composed.
 </p>
 <p>
  The <strong>canonical combining class tables</strong> contains the
  classification for the combining marks in Unicode, used to sort them for
  re-composing.
  The <abbr title="Basic Multilingual Plane (U+0000-U+FFFF)">BMP</abbr> table
  uses a UTF-16 code unit as the index, whereas the non-BMP table uses a pair
  of UTF-16 surrogates mapped into a 32-bit word as index.
  To improve look-up speed, portions of the table data is hardcoded into
  the look-up function.
  This hardcoding is validated by the generator script, to ensure that it
  still holds after an upgrade of the Unicode character database.
 </p>

 <h4 id="properties">Character properties tables</h4>
 <p>
  Both the <strong>character class</strong> and <strong>line-breaking
  properties tables</strong> are stored
  as run-length compressed tables with a flat structure for the first 256
  codepoints.
  The run-length compressed tables are split into one table of indices and
  one table of data each.
 </p>
 
 <h4 id="blocktypejoiningtypetables">Block type and joining type table</h4>
 <p>
  Both <strong>Block type</strong> and <strong>Joining type</strong> property 
  tables are stored as run-length compressed forms which are split into one 
  table of indices and one table of property values each. The first table of 
  each (containing indices to the second) is binary searched for performance.
 </p>
 
 <h4 id="extendedpropertiestables">Extended properties tables</h4>
 <p>
  All extended property tables (used by CheckPropertyValue method) are constructed 
  in this way that each element with even index is the begin of codepoints' 
  range for which the value is TRUE and each odd element defines codepoint 
  that starts the range with FALSE value.
 </p>
 
 <h4 id="casefoldingtables">Case folding tables</h4>
 <p>
  The full case folding table is just a sorted table of codepoints with it's mappings 
  and is not compressed in any way.
 </p>
 <p>
  The tables for simple case folding (both for BMP and for nonBMP) are stored as 
  run-length compressed tables where each of elements contain 3 fields: codepoint 
  starting the run, modifier and compression type. The compression type can be one of the following:
 </p>
 <dl>
  <dt>1. Constant delta</dt>
  <dd>
   When mapping to case folded form, the modifier value is added to the input code point.
  </dd>
  
  <dt>2. Set bit 0</dt>
  <dd>
   When mapping to case folded form, the less significant bit of the input code point is set.
  </dd>
  
  <dt>3. Clear bit 0</dt>
  <dd>
   When mapping to case folded form, the less significant bit of the input code point is cleared.
  </dd>
  
  <dt>4. Constant delta for even codepoints</dt>
  <dd>
   For even input code points in order to obtain the case folded form the modifier value is added to input code point.
   Odd code points are mapped to themselfs.
  </dd>
  
  <dt>5. Constant delta for odd codepoints</dt>
  <dd>
   For odd input code points in order to obtain the case folded form the modifier value is added to input code point.
   Even code points are mapped to themselfs.
  </dd>
 </dl>
 
 <h3 id="textsegmenterperformance">Text segmenter</h3>
 <p>
  The text segmenter implementation is
  <a href="segmenter.html">documented separately</a>.
 </p>

 <h3 id="bidiperformance">Bidirectional algorithm</h3>
 <p>
  The bidirectional algorithm implementation is
  <a href="bidi.html">discussed separately</a>.
 </p>

 <h3 id="possibleimprovements">Possible performance improvements</h3>

 <h4 id="normalizeimprove">Normalization</h4>
 <p>
  The "quick check" optimization mentioned in the normalization algorithm
  is not implemented, the only similar optimization done is that no
  normalization is done if the input string only contains characters in
  the Basic Latin (ASCII) range.
 </p>

 <h4 id="caseimprove">Case conversion</h4>
 <p>
  Some optimizations have been attempted in the casing conversions.
  <a href="https://bugs.opera.com/show_bug.cgi?id=264933">Reordering the
  ASCII tests</a> is one possibility, although looking at different input
  profiles yields different results on what is faster.
 </p>
 <p>
  Might be worth considering replacing the ASCII lookup with a table
  (will take 128 bytes in each direction since they only map to other
  ASCII characters).
 </p>
 <p>
  Research whether Unicode::Upper() (string) is really more often called
  directly than Unicode::ToUpper() (character), and check if splitting
  out common parts into a third function makes sense.
  Is the function call overhead too big?
 </p>

 <h4 id="segmenterimprove">Text segmenter</h4>
 <p>
  Investigate whether it is possible to improve the implementation of
  the text segmenter by not using a simple state machine as the ones
  <a href="segmenter.html">currently implemented</a>.
 </p>

</body>
</html>
